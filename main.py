import re
import pathlib
import argparse
import datetime
import numpy as np
import tensorflow as tf
import tensorflow_quantum as tfq

from models.classical_cnn import ClassicalCNN
from models.quantum_cnn import QuantumCNN, Q_SIZE, convert_to_circuit
from models.quantum_cnn1 import QuantumCNN1  # , NEW_SIZE
from models.quanvolutional_nn import QuanvolutionalNN, circuit
from utils.config import timeExec, MAIN_PATH, time, os


def main(arguments):
    print("LOADING AND PRE-PROCESSING DATA")

    dataset_base = MAIN_PATH + arguments.dataset

    # Create dataset of filepaths
    train_paths_ds = tf.data.Dataset.list_files(dataset_base + "/training/train/*/*")
    val_paths_ds = tf.data.Dataset.list_files(dataset_base + "/training/val/*/*")
    final_training_paths_ds = tf.data.Dataset.list_files(dataset_base + "/training/*/*/*")
    test_paths_ds = tf.data.Dataset.list_files(dataset_base + "/test/*/*")

    # STATS
    size_train = sum([len(files) for r, d, files in os.walk(dataset_base + "/training/train")])
    size_val = sum([len(files) for r, d, files in os.walk(dataset_base + "/training/val")])
    size_test = sum([len(files) for r, d, files in os.walk(dataset_base + "/test")])
    nclasses = len(CLASS_NAMES)

    # Print information on log
    # EXECUTION Info
    print_log(f"INFO EXECUTION:"
              f"\nmode = {arguments.mode}\nmodel = {arguments.model}\ndataset = {arguments.dataset}"
              f"\noutput_model = {arguments.output_model}\nepochs = {arguments.epochs}\n"
              f"batch_size = {arguments.batch_size}"f"\n----------------")

    # DATA Info
    print_log(f"INFO DATA:"
              f"\nnum_classes = {nclasses}\nclass_names= {CLASS_NAMES}"
              f"\nSize train-val-test= {size_train}-{size_val}-{size_test}"
              f"\nsize_img = {arguments.image_size}x{arguments.channels}")

    print_log("STARTING EXECUTION AT\t{}".format(time.strftime("%d-%m %H:%M:%S")), print_on_screen=True)

    # SELECTING MODELS
    model = _model_selection(arguments, nclasses)

    # --------------  TRAINING and VALIDATION part  --------------------

    if arguments.mode == "train-val":
        #  Use Dataset.map to create a dataset of image, label pairs
        # Set `num_parallel_calls` so multiple images are loaded/processed in parallel.
        lab_train_ds = train_paths_ds.map(process_path, num_parallel_calls=AUTOTUNE)
        lab_val_ds = val_paths_ds.map(process_path, num_parallel_calls=AUTOTUNE)

        train_ds = prepare_for_training(lab_train_ds)
        val_ds = prepare_for_training(lab_val_ds)

        if arguments.model == "CLASSIC_CNN":
            print_log('Start Training for {} epochs  '.format(arguments.epochs), print_on_screen=True)

            # Initialize callbacks for Tensorboard
            log_fit = "tensorboard/fit/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
            tensorboard_callback_fit = tf.keras.callbacks.TensorBoard(log_dir=log_fit, histogram_freq=1)

            train_results = model.fit(x=train_ds, batch_size=arguments.batch_size, epochs=arguments.epochs,
                                      validation_data=val_ds, callbacks=[tensorboard_callback_fit])

            del train_ds, val_ds
        elif arguments.model == "QUANTUM_CNN":
            train_data = [(images.numpy(), labels.numpy()) for images, labels in train_ds]
            val_data = [(images.numpy(), labels.numpy()) for images, labels in val_ds]

            # TODO Ricontrollare bene il caricamento del dataset
            # train_images = train_data[0][0]
            # train_labels = train_data[0][1]
            #
            # val_images = val_data[0][0]
            # val_labels = val_data[0][1]
            #
            # train_images_tfcirc, val_images_tfcirc = quantum_preprocess_train_val(train_images, val_images)
            #
            # print_log('Start Training for {} epochs  '.format(arguments.epochs), print_on_screen=True)
            #
            # # Initialize callbacks for Tensorboard
            # log_fit = "tensorboard/fit/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
            # tensorboard_callback_fit = tf.keras.callbacks.TensorBoard(log_dir=log_fit, histogram_freq=1)
            #
            # train_results = model.fit(x=train_images_tfcirc, y=train_labels, batch_size=arguments.batch_size,
            #                           epochs=arguments.epochs, validation_data=(val_images_tfcirc, val_labels),
            #                           callbacks=[tensorboard_callback_fit])
            #
            # del train_images, val_images, train_labels, val_labels, train_images_tfcirc, val_images_tfcirc

            train_images = []
            train_labels = []
            val_images = []
            val_labels = []

            for element in train_data:
                train_images.append(element[0])
                train_labels.append(element[1])

            for element in val_data:
                val_images.append(element[0])
                val_labels.append(element[1])

            del train_images[-1]
            del train_labels[-1]
            del val_images[-1]
            del val_labels[-1]

            train_images_tfcirc = [quantum_preprocess(train) for train in train_images]
            val_images_tfcirc = [quantum_preprocess(val) for val in val_images]

            train_images_tfcirc = tf.convert_to_tensor(train_images_tfcirc)
            val_images_tfcirc = tf.convert_to_tensor(val_images_tfcirc)
            train_labels = tf.convert_to_tensor(train_labels)
            val_labels = tf.convert_to_tensor(val_labels)

            print_log('Start Training for {} epochs  '.format(arguments.epochs), print_on_screen=True)

            # Initialize callbacks for Tensorboard
            log_fit = "tensorboard/fit/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
            tensorboard_callback_fit = tf.keras.callbacks.TensorBoard(log_dir=log_fit, histogram_freq=1)

            train_results = model.fit(x=train_images_tfcirc, y=train_labels, batch_size=arguments.batch_size,
                                      epochs=arguments.epochs, validation_data=(val_images_tfcirc, val_labels),
                                      callbacks=[tensorboard_callback_fit])

            del train_images, val_images, train_labels, val_labels, train_images_tfcirc, val_images_tfcirc
        elif arguments.model == "QUANTUM_CNN1":
            # train_data = [(images.numpy(), labels.numpy()) for images, labels in train_ds]
            # val_data = [(images.numpy(), labels.numpy()) for images, labels in val_ds]
            #
            # train_images = train_data[0][0]
            # train_labels = train_data[0][1]
            #
            # val_images = val_data[0][0]
            # val_labels = val_data[0][1]
            #
            # train_images = tf.image.resize(train_images[:], (NEW_SIZE, NEW_SIZE)).numpy()
            # val_images = tf.image.resize(val_images[:], (NEW_SIZE, NEW_SIZE)).numpy()
            #
            # train_labels = train_labels[:]
            # val_labels = val_labels[:]
            #
            # print_log('Start Training for {} epochs  '.format(arguments.epochs), print_on_screen=True)
            #
            # # Initialize callbacks for Tensorboard
            # log_fit = "tensorboard/fit/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
            # tensorboard_callback_fit = tf.keras.callbacks.TensorBoard(log_dir=log_fit, histogram_freq=1)
            #
            # train_results = model.fit(x=train_images, y=train_labels, batch_size=arguments.batch_size,
            #                           epochs=arguments.epochs, validation_data=(val_images, val_labels),
            #                           callbacks=[tensorboard_callback_fit])
            #
            # del train_images, val_images, train_labels, val_labels

            print_log('Start Training for {} epochs  '.format(arguments.epochs), print_on_screen=True)

            # Initialize callbacks for Tensorboard
            log_fit = "tensorboard/fit/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
            tensorboard_callback_fit = tf.keras.callbacks.TensorBoard(log_dir=log_fit, histogram_freq=1)

            train_results = model.fit(x=train_ds, batch_size=arguments.batch_size,
                                      epochs=arguments.epochs, validation_data=val_ds,
                                      callbacks=[tensorboard_callback_fit])

            del train_ds, val_ds
        elif arguments.model == "QUANV_CNN":
            train_data = [(images.numpy(), labels.numpy()) for images, labels in train_ds]
            val_data = [(images.numpy(), labels.numpy()) for images, labels in val_ds]

            train_images = train_data[0][0]
            train_labels = train_data[0][1]

            val_images = val_data[0][0]
            val_labels = val_data[0][1]

            if arguments.preprocess == "y":
                print_log(f"\nimages preprocess = yes", print_on_screen=True)

                quanv_preprocess_train_val(train_images, val_images)
            else:
                print_log(f"\nimages preprocess = no", print_on_screen=True)

            q_train_images = np.load(SAVE_PATH + "q_train_images.npy")
            q_val_images = np.load(SAVE_PATH + "q_validation_images.npy")

            print_log('Start Training for {} epochs  '.format(arguments.epochs), print_on_screen=True)

            # Initialize callbacks for Tensorboard
            log_fit = "tensorboard/fit/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
            tensorboard_callback_fit = tf.keras.callbacks.TensorBoard(log_dir=log_fit, histogram_freq=1)

            train_results = model.fit(q_train_images, train_labels, steps_per_epoch=arguments.batch_size,
                                      epochs=arguments.epochs, validation_data=(q_val_images, val_labels),
                                      callbacks=[tensorboard_callback_fit])

            del train_images, val_images, train_labels, val_labels, q_train_images, q_val_images
        else:
            train_results = None

        print_log("\ttrain_loss:{} \n\ttrain_acc:{} \n\ttrain_prec:{} \n\ttrain_rec:{} \n"
                  "\tval_loss:{} \n\tval_acc:{} \n\tval_prec:{} \n\tval_rec:{}"
                  .format(train_results.history['loss'], train_results.history['prec'],
                          train_results.history['rec'],
                          train_results.history['acc'],
                          train_results.history['val_loss'], train_results.history['val_acc'],
                          train_results.history['val_prec'], train_results.history['val_rec']))

    # --------------  FINAL TRAINING and TEST part  --------------------

    if arguments.mode == "train-test":
        #  Use Dataset.map to create a dataset of image, label pairs
        # Set `num_parallel_calls` so multiple images are loaded/processed in parallel.
        lab_final_train_ds = final_training_paths_ds.map(process_path, num_parallel_calls=AUTOTUNE)
        lab_test_ds = test_paths_ds.map(process_path, num_parallel_calls=AUTOTUNE)

        fin_train_ds = prepare_for_training(lab_final_train_ds)
        test_ds = prepare_for_training(lab_test_ds)

        if arguments.model == "CLASSIC_CNN":
            # Train the model over the entire total_training set and then test
            print_log('Start Final Training for {} epochs  '.format(arguments.epochs), print_on_screen=True)
            final_train_results = model.fit(x=fin_train_ds, batch_size=arguments.batch_size, epochs=arguments.epochs)
            print_log("\ttrain_loss:{} \n\ttrain_acc:{} \n\ttrain_prec:{} \n\ttrain_rec:{} \n"
                      .format(final_train_results.history['loss'], final_train_results.history['prec'],
                              final_train_results.history['rec'], final_train_results.history['acc']))

            # Test the trained model over the test set
            print_log('Start Test', print_on_screen=True)
            results = model.evaluate(test_ds)
            print_log("\ttest loss:{} \n\ttest accuracy:{}".format(results[0], results[1]), print_on_screen=True)
            print_log("\tPrec:{} \n\tRecall:{}".format(results[2], results[3]), print_on_screen=True)

            del fin_train_ds, test_ds
        elif arguments.model == "QUANTUM_CNN":
            fin_train_data = [(images.numpy(), labels.numpy()) for images, labels in fin_train_ds]
            test_data = [(images.numpy(), labels.numpy()) for images, labels in test_ds]

            final_train_images = fin_train_data[0][0]
            final_train_labels = fin_train_data[0][1]

            test_images = test_data[0][0]
            test_labels = test_data[0][1]

            final_train_images_tfcirc, test_images_tfcirc = quantum_preprocess_train_test(final_train_images, test_images)

            # Train the model over the entire total_training set and then test
            print_log('Start Final Training for {} epochs  '.format(arguments.epochs), print_on_screen=True)
            final_train_results = model.fit(x=final_train_images_tfcirc, y=final_train_labels,
                                            batch_size=arguments.batch_size, epochs=arguments.epochs)
            print_log("\ttrain_loss:{} \n\ttrain_acc:{} \n\ttrain_prec:{} \n\ttrain_rec:{} \n"
                      .format(final_train_results.history['loss'], final_train_results.history['prec'],
                              final_train_results.history['rec'], final_train_results.history['acc']))

            # Test the trained model over the test set
            print_log('Start Test', print_on_screen=True)
            results = model.evaluate(test_images_tfcirc, test_labels)
            print_log("\ttest loss:{} \n\ttest accuracy:{}".format(results[0], results[1]), print_on_screen=True)
            print_log("\tPrec:{} \n\tRecall:{}".format(results[2], results[3]), print_on_screen=True)

            del final_train_images, test_images, final_train_labels, test_labels, final_train_images_tfcirc, \
                test_images_tfcirc
        elif arguments.model == "QUANTUM_CNN1":
            # fin_train_data = [(images.numpy(), labels.numpy()) for images, labels in fin_train_ds]
            # test_data = [(images.numpy(), labels.numpy()) for images, labels in test_ds]
            #
            # final_train_images = fin_train_data[0][0]
            # final_train_labels = fin_train_data[0][1]
            #
            # test_images = test_data[0][0]
            # test_labels = test_data[0][1]
            #
            # final_train_images = tf.image.resize(final_train_images[:], (NEW_SIZE, NEW_SIZE)).numpy()
            # test_images = tf.image.resize(test_images[:], (NEW_SIZE, NEW_SIZE)).numpy()
            #
            # final_train_labels = final_train_labels[:]
            # test_labels = test_labels[:]
            #
            # # Train the model over the entire total_training set and then test
            # print_log('Start Final Training for {} epochs  '.format(arguments.epochs), print_on_screen=True)
            # final_train_results = model.fit(x=final_train_images, y=final_train_labels,
            #                                 batch_size=arguments.batch_size, epochs=arguments.epochs)
            # print_log("\ttrain_loss:{} \n\ttrain_acc:{} \n\ttrain_prec:{} \n\ttrain_rec:{} \n"
            #           .format(final_train_results.history['loss'], final_train_results.history['prec'],
            #                   final_train_results.history['rec'], final_train_results.history['acc']))
            #
            # # Test the trained model over the test set
            # print_log('Start Test', print_on_screen=True)
            # results = model.evaluate(test_images, test_labels)
            # print_log("\ttest loss:{} \n\ttest accuracy:{}".format(results[0], results[1]), print_on_screen=True)
            # print_log("\tPrec:{} \n\tRecall:{}".format(results[2], results[3]), print_on_screen=True)
            #
            # del final_train_images, test_images, final_train_labels, test_labels

            # Train the model over the entire total_training set and then test
            print_log('Start Final Training for {} epochs  '.format(arguments.epochs), print_on_screen=True)
            final_train_results = model.fit(x=fin_train_ds, batch_size=arguments.batch_size, epochs=arguments.epochs)
            print_log("\ttrain_loss:{} \n\ttrain_acc:{} \n\ttrain_prec:{} \n\ttrain_rec:{} \n"
                      .format(final_train_results.history['loss'], final_train_results.history['prec'],
                              final_train_results.history['rec'], final_train_results.history['acc']))

            # Test the trained model over the test set
            print_log('Start Test', print_on_screen=True)
            results = model.evaluate(test_ds)
            print_log("\ttest loss:{} \n\ttest accuracy:{}".format(results[0], results[1]), print_on_screen=True)
            print_log("\tPrec:{} \n\tRecall:{}".format(results[2], results[3]), print_on_screen=True)

            del fin_train_ds, test_ds
        elif arguments.model == "QUANV_CNN":
            fin_train_data = [(images.numpy(), labels.numpy()) for images, labels in fin_train_ds]
            test_data = [(images.numpy(), labels.numpy()) for images, labels in test_ds]

            final_train_images = fin_train_data[0][0]
            final_train_labels = fin_train_data[0][1]

            test_images = test_data[0][0]
            test_labels = test_data[0][1]

            if arguments.preprocess == "y":
                print_log(f"\nimages preprocess = {arguments.preprocess}", print_on_screen=True)

                quanv_preprocess_train_test(final_train_images, test_images)

            q_final_train_images = np.load(SAVE_PATH + "q_final_train_images.npy")
            q_test_images = np.load(SAVE_PATH + "q_test_images.npy")

            # Train the model over the entire total_training set and then test
            print_log('Start Final Training for {} epochs  '.format(arguments.epochs), print_on_screen=True)
            final_train_results = model.fit(q_final_train_images, final_train_labels,
                                            steps_per_epoch=arguments.batch_size,
                                            epochs=arguments.epochs)
            print_log("\ttrain_loss:{} \n\ttrain_acc:{} \n\ttrain_prec:{} \n\ttrain_rec:{} \n"
                      .format(final_train_results.history['loss'], final_train_results.history['prec'],
                              final_train_results.history['rec'], final_train_results.history['acc']))

            # Test the trained model over the test set
            print_log('Start Test', print_on_screen=True)
            results = model.evaluate(q_test_images, test_labels)
            print_log("\ttest loss:{} \n\ttest accuracy:{}".format(results[0], results[1]), print_on_screen=True)
            print_log("\tPrec:{} \n\tRecall:{}".format(results[2], results[3]), print_on_screen=True)

            del final_train_images, test_images, final_train_labels, test_labels, q_final_train_images, q_test_images
        else:
            results = None

        try:
            # F-measure calculated as (2 * Prec * Recall)/(Prec + Recall)
            print_log("\tF-Measure:{} \n\tAUC:{}"
                      .format((2 * results[2] * results[3]) / (results[2] + results[3]), results[4]),
                      print_on_screen=True)
        except ZeroDivisionError:
            print_log("\tF-Measure:{} \n\tAUC:{}"
                      .format("Error", results[4]), print_on_screen=True)

        # save model and architecture to single file
        if arguments.output_model is not None:
            model.save(MAIN_PATH + 'model_saved/{}_m{}'.format(arguments.output_model, arguments.model))
            model.save_weights(MAIN_PATH + 'model_saved/{}_m{}_weights'.format(arguments.output_model, arguments.model))

    print_log("ENDING EXECUTION AT\t{}".format(time.strftime("%d-%m %H:%M:%S")), print_on_screen=True)


def parse_args():
    parser = argparse.ArgumentParser(
        description='Deep Learning Image Malware Classification')
    group = parser.add_argument_group('Arguments')
    # REQUIRED Arguments
    group.add_argument('-m', '--model', required=True, type=str,
                       choices=['CLASSIC_CNN', 'QUANTUM_CNN', 'QUANTUM_CNN1', 'QUANV_CNN'],
                       help='CLASSIC_CNN, QUANTUM_CNN, QUANTUM_CNN1, QUANV_CNN')
    group.add_argument('-d', '--dataset', required=True, type=str,
                       help='the dataset path, must have the folder structure: training/train, training/val and test,'
                            'in each of this folders, one folder per class (see dataset_test)')
    # OPTIONAL Arguments
    group.add_argument('-o', '--output_model', required=False, type=str, default=None,
                       help='Name of model to store')
    group.add_argument('-e', '--epochs', required=False, type=int, default=10,
                       help='number of epochs')
    group.add_argument('-b', '--batch_size', required=False, type=int, default=32)
    group.add_argument('-i', '--image_size', required=False, type=str, default="250x1",
                       help='FORMAT ACCEPTED = SxC , the Size (SIZExSIZE) and channel of the images in input '
                            '(reshape will be applied)')
    group.add_argument('-w', '--weights', required=False, type=str, default=None,
                       help="If you do not want random initialization of the model weights "
                            "(ex. 'imagenet' or path to weights to be loaded)")
    group.add_argument('--mode', required=False, type=str, default='train-val', choices=['train-val', 'train-test',
                                                                                         'test'],
                       help="Choose which mode run between 'train-val' (default) or 'train-test'."
                            "The 'train-val' mode will run a phase of training and validation on the training and "
                            "validation set, while the 'train-test' mode will run a phase of training on the "
                            "training+validation sets and then test on the test set.")
    group.add_argument('-p', '--preprocess', required=False, type=str, default="y",
                       help='Specifies if image quantum preprocess is needed [y or n]')
    group.add_argument('-r', '--resize', required=False, type=int, default=10,
                       help='Specifies images resizing for QUANTUM_CNN1 (usually 10')
    # FLAGS
    group.add_argument('--exclude_top', dest='include_top', action='store_false',
                       help='Exclute the fully-connected layer at the top pf the network (default INCLUDE)')
    group.set_defaults(include_top=True)
    arguments = parser.parse_args()
    return arguments


def _check_args(arguments):
    if re.match(r"^\d{2,4}x([13])$", arguments.image_size):
        img_size = arguments.image_size.split("x")[0]
        channels = arguments.image_size.split("x")[1]
        setattr(arguments, "image_size", int(img_size))
        setattr(arguments, "channels", int(channels))
    else:
        print('Invalid image_size, exiting...')
        exit()
    if not os.path.isdir(MAIN_PATH + arguments.dataset):
        print('Cannot find dataset in {}, exiting...'.format(arguments.dataset))
        exit()
    # Check Dataset struct: should be in folder tree training/[train|val] e test
    if not os.path.isdir(MAIN_PATH + arguments.dataset + "/test") or \
            not os.path.isdir(MAIN_PATH + arguments.dataset + "/training/val") or \
            not os.path.isdir(MAIN_PATH + arguments.dataset + "/training/train"):
        print(f"Dataset '{arguments.dataset}' should contain folders 'test, training/train and training/val'...")
        exit()


def _model_selection(arguments, nclasses):
    model = None
    print("INITIALIZING MODEL")

    if arguments.model == "CLASSIC_CNN":
        model_class = ClassicalCNN(nclasses, arguments.image_size, arguments.channels)
    elif arguments.model == "QUANTUM_CNN":
        model_class = QuantumCNN(nclasses, arguments.image_size, arguments.channels)
    elif arguments.model == "QUANTUM_CNN1":
        model_class = QuantumCNN1(nclasses, arguments.image_size, arguments.channels)
    elif arguments.model == "QUANV_CNN":
        model_class = QuanvolutionalNN(nclasses, arguments.image_size, arguments.channels)
    else:
        print("model {} not implemented yet...".format(arguments.model))
        model_class = None
        exit()

    model = model_class.build()
    return model


def get_label(file_path):
    # convert the path to a list of path components
    parts = tf.strings.split(file_path, os.path.sep)
    # The second to last is the class-directory
    # cast to float32 for one_hot encode (otherwise TRUE/FALSE tensor)
    return tf.cast(parts[-2] == CLASS_NAMES, tf.float32)


def decode_img(img):
    # convert the compressed string to a 3D uint8 tensor
    img = tf.image.decode_png(img, channels=CHANNELS)  # tf.image.decode_jpeg(img, channels=CHANNELS)
    # Use `convert_image_dtype` to convert to floats in the [0,1] range.
    img = tf.image.convert_image_dtype(img, tf.float32)
    # resize the image to the desired size.
    return tf.image.resize(img, [IMG_DIM, IMG_DIM])


def process_path(file_path):
    label = get_label(file_path)
    # load the raw data from the file as a string
    img = tf.io.read_file(file_path)
    img = decode_img(img)
    return img, label


def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000, loop=False):
    # IF it is a small dataset, only load it once and keep it in memory.
    # OTHERWISE use `.cache(filename)` to cache preprocessing work for datasets that don't fit in memory.
    if cache:
        if isinstance(cache, str):
            ds = ds.cache(cache)
        else:
            ds = ds.cache()

    ds = ds.shuffle(buffer_size=shuffle_buffer_size)

    # Repeat forever
    if loop:
        ds = ds.repeat()

    ds = ds.batch(BATCH_SIZE)

    # `prefetch` lets the dataset fetch batches in the background while the model
    # is training.
    ds = ds.prefetch(buffer_size=AUTOTUNE)

    return ds


def print_log(string, print_on_screen=False, print_on_file=True):
    if print_on_screen:
        print(string)
    if print_on_file:
        with open(MAIN_PATH + 'logs/' + timeExec + ".results", 'a') as logfile:
            logfile.write(string + "\n")


def quantum_preprocess(train):
    train_images_small = tf.image.resize(train, (Q_SIZE, Q_SIZE)).numpy()

    train_images_bin = np.array(train_images_small > THRESHOLD, dtype=np.float32)

    train_images_circ = [convert_to_circuit(x) for x in train_images_bin]

    train_images_tfcirc = tfq.convert_to_tensor(train_images_circ)

    del train_images_bin, train_images_circ

    return train_images_tfcirc


def quantum_preprocess_train_val(train, val):
    train_images_small = tf.image.resize(train, (Q_SIZE, Q_SIZE)).numpy()
    val_images_small = tf.image.resize(val, (Q_SIZE, Q_SIZE)).numpy()

    train_images_bin = np.array(train_images_small > THRESHOLD, dtype=np.float32)
    val_images_bin = np.array(val_images_small > THRESHOLD, dtype=np.float32)

    train_images_circ = [convert_to_circuit(x) for x in train_images_bin]
    val_images_circ = [convert_to_circuit(x) for x in val_images_bin]

    train_images_tfcirc = tfq.convert_to_tensor(train_images_circ)
    val_images_tfcirc = tfq.convert_to_tensor(val_images_circ)

    del train_images_bin, train_images_circ, val_images_bin, val_images_circ

    return train_images_tfcirc, val_images_tfcirc


def quantum_preprocess_train_test(train, test):
    final_train_images_small = tf.image.resize(train, (4, 4)).numpy()
    test_images_small = tf.image.resize(test, (4, 4)).numpy()

    final_train_images_bin = np.array(final_train_images_small > THRESHOLD, dtype=np.float32)
    test_images_bin = np.array(test_images_small > THRESHOLD, dtype=np.float32)

    final_train_images_circ = [convert_to_circuit(x) for x in final_train_images_bin]
    test_images_circ = [convert_to_circuit(x) for x in test_images_bin]

    final_train_images_tfcirc = tfq.convert_to_tensor(final_train_images_circ)
    test_images_tfcirc = tfq.convert_to_tensor(test_images_circ)

    del final_train_images_small, test_images_small, final_train_images_bin, test_images_bin, \
        final_train_images_circ, test_images_circ

    return final_train_images_tfcirc, test_images_tfcirc


def quanv(image):
    new_img_dim = IMG_DIM // QUANV_FILTER_DIM
    """Convolves the input image with many applications of the same quantum circuit."""
    out = np.zeros((new_img_dim, new_img_dim, CHANNELS))

    # Loop over the coordinates of the top-left pixel of 2X2 squares
    for j in range(0, IMG_DIM, QUANV_FILTER_DIM):
        for h in range(0, IMG_DIM, QUANV_FILTER_DIM):
            # Process a squared 2x2 region of the image with a quantum circuit
            q_results = circuit(
                [
                    image[j, h, 0],
                    image[j, h + 1, 0],
                    image[j + 1, h, 0],
                    image[j + 1, h + 1, 0]
                ]
            )
            # Assign expectation values to different channels of the output pixel (j/2, k/2)
            for w in range(CHANNELS):
                out[j // QUANV_FILTER_DIM, h // QUANV_FILTER_DIM, w] = q_results[w]
    return out


def quanv_preprocess_train_val(train, val):
    q_train_images = []
    print("Quantum pre-processing of training images:")
    for idx, img in enumerate(train):
        print(f'{idx + 1}/{len(train)}')
        q_train_images.append(quanv(img))
    q_train_images = np.asarray(q_train_images)

    q_val_images = []
    print("\nQuantum pre-processing of validation images:")
    for idx, img in enumerate(val):
        print(f'{idx + 1}/{len(val)}')
        q_val_images.append(quanv(img))
    q_val_images = np.asarray(q_val_images)

    # Save pre-processed images
    np.save(SAVE_PATH + "q_train_images.npy", q_train_images)
    np.save(SAVE_PATH + "q_validation_images.npy", q_val_images)


def quanv_preprocess_train_test(train, test):
    q_train_images = []
    print("Quantum pre-processing of training images:")
    for idx, img in enumerate(train):
        print(f'{idx + 1}/{len(train)}')
        q_train_images.append(quanv(img))
    q_train_images = np.asarray(q_train_images)

    q_test_images = []
    print("\nQuantum pre-processing of test images:")
    for idx, img in enumerate(test):
        print(f'{idx + 1}/{len(test)}')
        q_test_images.append(quanv(img))
    q_test_images = np.asarray(q_test_images)

    # Save pre-processed images
    np.save(SAVE_PATH + "q_final_train_images.npy", q_train_images)
    np.save(SAVE_PATH + "q_test_images.npy", q_test_images)


if __name__ == '__main__':
    start = time.perf_counter()
    args = parse_args()
    _check_args(args)
    # GLOBAL SETTINGS FOR THE EXECUTIONS
    # Reduce verbosity for Tensorflow Warnings and set dtype for layers
    # tf.keras.backend.set_floatx('float64')
    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
    AUTOTUNE = tf.data.experimental.AUTOTUNE
    CHANNELS = args.channels
    IMG_DIM = args.image_size
    CLASS_NAMES = np.array([item.name for item in pathlib.Path(MAIN_PATH + args.dataset + "/training/train").glob('*')])
    BATCH_SIZE = args.batch_size

    THRESHOLD = 0.5
    QUANV_FILTER_DIM = 2
    SAVE_PATH = "quanv_images/"  # Data saving folder

    # Check if tensorflow can access the GPU
    device_name = tf.test.gpu_device_name()
    if not device_name:
        print('GPU device not found...')
    else:
        print('Found GPU at: {}'.format(device_name))

    main(args)
    end = time.perf_counter()
    print()
    print_log("EX. TIME: {} ".format(str(datetime.timedelta(seconds=end - start))), print_on_screen=True)
